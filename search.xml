<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python避坑]]></title>
    <url>%2FPython%E9%81%BF%E5%9D%91%2F</url>
    <content type="text"><![CDATA[记录一些Python编程的经验教训 codecs.open和open的区别 Python3直接用open。 Python2.x下用codecs.open，特别是有中文的情况，然后也可以避免踩到2.6下面io.open的坑。 如果希望代码同时兼容Python2和Python3，那么推荐用codecs.open。 资料百度知道]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于规则的分词实现]]></title>
    <url>%2F%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E8%AF%8D%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[最大匹配法（MM）实现案例 最大匹配法（MM）实现案例词典文件word.txt12345678910北京天安门四维图新大厦广场路上前往火车站公司经过 停用词文件stoplis.txt12345678@#￥%&amp;_=+ 最大匹配法 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import codecsclass MM: def __init__(self): self.dic = &#123;&#125; self.stoplis = &#123;&#125; self.load() self.max_chars = 0 # 遍历分词字典，获得最大分词长度 for key in self.dic: if len(key) &gt; self.max_chars: self.max_chars = len(key) def load(self): # 获得分词字典，存储为字典形式 f1 = codecs.open('words.txt', 'r', encoding='utf8') while 1: line = f1.readline() if len(line) == 0: break term = line.strip().replace('\r\n', '') # 去除字符串两侧的换行符，避免取最大分词长度时出差错 self.dic[term] = 1 f1.close # 获得停用词典，存储为字典形式 f2 = codecs.open('stoplis.txt', 'r', encoding='utf8') while 1: line = f2.readline() if len(line) == 0: break term = line.strip() self.stoplis[term] = 1 f2.close # 正向最大匹配分词算法 def analyze(self, chars): # 获得需要分词的文本，为字符串形式 # 去除字符串两侧的换行符，避免截词时出差错 chars = chars.strip().replace('\r\n', '') # 定义一个空列表来存储分词结果 words = [] n = 0 while n &lt; len(chars): matched = 0 for i in range(self.max_chars, 0, -1): s = chars[n:n + i] # 判断所截取字符串是否在分词词典和停用词典内 if s in self.dic: if s in self.stoplis: matched = 1 n = n + i break else: words.append(s) matched = 1 n = n + i break if s in self.stoplis: matched = 1 n = n + i break if not matched: words.append(chars[n]) n = n + 1 print("/".join(words))if __name__ == '__main__': mm = MM() mm.analyze("我去北京四维图新大厦的路上经过@火车站和@天安门广场。") 测试结果1我/去/北京/四维图新/大厦/的/路上/经过/火车站/和/天安门/广场/。]]></content>
      <categories>
        <category>中文分词</category>
      </categories>
      <tags>
        <tag>最大匹配法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSA算法]]></title>
    <url>%2FRSA%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[RSA公钥加密算法是1977年由Ron Rivest、Adi Shamirh和LenAdleman在（美国麻省理工学院）开发的。RSA取名来自开发他们三者的名字。RSA是目前最有影响力的公钥加密算法，它能够抵抗到目前为止已知的所有密码攻击，已被ISO推荐为公钥数据加密标准。RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。 RSA加密的安全性人类已经分解的最大整数（232个十进制位，768个二进制位）。比它更大的因数分解，还没有被报道过，因此目前被破解的最长RSA密钥就是768位。而RSA加密一般使用1024位或者2048位，基本可以理解为不可破解 RSA加密解密原理 X-&gt;Y加密公式: $X^E{mod}N=Y$Y-&gt;X解密公式: $Y^D{mod}N=N$ 1. 将N和E封装成公钥，N和D封装成私钥2. N为两个不等质数的乘积3. E与φ(N) 互素（互为质数）4. D满足$D \times E \equiv 1({mod}φ(N))$ 即 $D \times E-1=k \times φ(N)$ 案例计算 选择两个不等质数p,q (实际密钥一般为1024位或2048位)p=61,q=53 计算乘积nn = p*q = 3233 (二进制110010100001，只有12位) 计算n的欧拉函数φ(n)φ(n) = φ(p)*φ(q)= (p-1)(q-1) = 3120 (质数的因子只有1和本身—一个质数p的欧拉函数等于p-1) 随机选择一个整数e，条件是1&lt; e &lt; φ(n)，且e与φ(n) 互质。取e = 17 (实际应用中，常常选择$2^16=65537$)。 计算e对于φ(n)的模反元素ded = 1 (mod φ(n)) 即 ed -1 = kφ(n)17d -1 = k3120 即 17d +3120k = 1 得 d = 2753 将n和e封装成公钥，n和d封装成私钥加密使用 (3233,17)，解密使用(3233,2723) 加密(‘a’=65) n = 3233,e = 17所有字符串都可以使用ascil码/unicode值来表示，假设一个字符 m = a，ascii码为65,需要满足 m &lt; n 对他进行加密m^e ≡ c (mod n),c为加密字符串(65^17)%3233 = c 得 c = 2790密码为 2790 解密(2790) n = 3233,d = 2723c^d ≡ m (mod n) 即可得到mm = (2790^2723) %3233 得 m = 65内容为65=’a’ RSA算法相关数学理论 互素|互为质数python12345678910111213141516'''定义法 生成质数'''def primes(start, stop): if start &lt; 2: start = 2 for i in range(start, stop+1): for j in range(2, i): if i % j == 0: break else: yield i# 0到200之间的素数for x in primes(0, 200): print(x) python123456789101112131415161718192021222324252627282930313233343536'''埃氏筛法 生成质数（1）先把1删除（现今数学界1既不是质数也不是合数）（2）读取队列中当前最小的数2，然后把2的倍数删去（3）读取队列中当前最小的数3，然后把3的倍数删去（4）读取队列中当前最小的数5，然后把5的倍数删去（5）如上所述直到需求的范围内所有的数均删除或读取'''# 生成一个奇数生成器。def odd_iter(): n = 1 while True: n = n + 2 yield n# 过滤掉n的倍数的数。def not_divisible(n): return lambda x: x % n &gt; 0# 获取当前序列的第一个元素，然后删除后面序列该元素倍数的数，然后构造新序列。def primes(): yield 2 it = odd_iter() while True: n = next(it) yield n it = filter(not_divisible(n), it)# 获取 start 到 stop 之间的素数。def printPrimes(start, stop): # start, stop = 10, 2000 for n in primes(): if n &gt; start and n &lt; stop: print(n, end=',') elif n &gt; stop: break 欧拉函数欧拉函数的定义：对正整数n，欧拉函数是少于或等于n的数中与n互质的数的数目。例如euler(8)=4，因为1,3,5,7均和8互质。Euler函数表达通式：euler(x)=x(1-1/p1)(1-1/p2)(1-1/p3)(1-1/p4)…(1-1/pn),其中p1,p2……pn为x的所有素因数，x是不为0的整数。euler(1)=1（唯一和1互质的数就是1本身）。欧拉公式的延伸：一个数的与其互质的数(&lt;n)的总和是euler(n)*n/2 根据Euler函数表达通式直接求法：python123456789101112131415# 直接求解欧拉函数def euler(n): res = n a = n i = 2 #i表示小于a的所有质数 while i*i &lt;= a: if a % i == 0: # 先进行除法是为了防止中间数据的溢出 res = res / i * (i-1) while a % i == 0: a /= i i += 1 if a &gt; 1: res = res / a * (a-1) return res 欧拉定理费尔马小定理 模反元素 扩展欧几里得算法辗转相除法 python123456# 辗转相除法求最大公因数def gcd(a, b): if b == 0: return a else: return gcd(b, a % b) 快速幂取模算法 java12345678910111213141516/** * 快速幂取模 计算 (a^b) %c */private static int quick(int a,int b,int c) &#123; int ans=1; //记录结果 a=a%c; //预处理，使得a处于c的数据范围之下 while(b!=0) &#123; if((b&amp;1)==1)&#123; //1即是0000000000000001，判断个位是否是1.如果b的二进制位是1，那么我们的结果是要参与运算的 ans=(ans*a)%c; &#125; b&gt;&gt;=1; //二进制的移位操作，相当于每次除以2，用二进制看，就是我们不断的遍历b的二进制位 a=(a*a)%c; //不断的加倍 &#125; return ans;&#125; 参考资料ab6326795 公钥，私钥和数字签名这样最好理解不会汪汪的猫咪 CSDN RSA加密的原理——为什么被公钥加密的可以被私钥解密？Warning 扩展欧几里得算法详解sortmin CSDN 欧拉函数的两种基本写法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>公钥加密算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2FGit%2F</url>
    <content type="text"><![CDATA[生成秘钥、git暂存区 git安装配置相关生成秘钥1ssh-keygen -t rsa -C "youremail@example.com" git本地使用git stash切换其他分支前，暂存当前分支的修改12# 将当前工作区的暂存区的数据收入stashgit stash git stash 不会存储未跟踪的文件，所以使用该指令操作如下比较安全，执行stash后内容为最近commit节点内容。12345678910# 1.看有没有未追踪的文件git status# 2.如果有未追踪的文件，先addgit add .# 3.可暂存修改了git stash# 或git stash save '本次暂存的标识名字' 查看存储列表1git stash list 切换回分支后，恢复暂存的修改12345678910111213# 直接恢复最近的暂存，pop后暂存列表清空git stash popgit stash pop stash@&#123;0&#125;# 也有其他指令可以恢复,apply后暂存列表不清空git stash applygit stash apply stash@&#123;0&#125;# 手动清理暂存列表#删除某个暂存, 暂存记录保存在list内,需要通过list索引index取出恢复git stash drop stash@&#123;index&#125;#删除全部暂存git stash clear]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>经验</tag>
        <tag>git</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dijkstra算法]]></title>
    <url>%2FDijkstra%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[迪杰斯特拉(Dijkstra)算法是典型最短路径算法，用于计算一个节点到其他节点的最短路径。它的主要特点是以起始点为中心向外层层扩展(广度优先搜索思想)，直到扩展到终点为止。 序号 S集合 U集合 1 A=0 (A)B=6,(A)C=3,D=∞,E=∞,F=∞ 2 A=0,A-C=3 (C)B=5,(C)D=6,(C)E=7,F=∞ 3 A=0,A-C=3,A-C-B=5 (C)D=6,(C)E=7,F=∞ 4 A=0,A-C=3,A-C-B=5,A-C-D=6 (C)E=7,(D)F=9 5 A=0,A-C=3,A-C-B=5,A-C-D=6,A-C-E=7 (D)F=9 6 A=0,A-C=3,A-C-B=5,A-C-D=6,A-C-E=7,A-C-D-F=9 当U集合为空时，探索路径结束，A-F最短路径:A-C-D-F=9 S集合 已探索最短路径的顶点集合（记录最短路径和距离）U集合 未确定最短路径的顶点集合（记录短路径和距离） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Dijkstra &#123; public static final int M = 10000; // 代表正无穷 public static String[] nodes = &#123;"A","B","C","D","E","F"&#125;; public static void main(String[] args) &#123; // 二维数组每一行分别是 A、B、C、D、E 各点到其余点的距离, // A -&gt; A 距离为0, 常量M 为正无穷 int[][] weight1 = &#123; &#123;0,6,3,M,M,M&#125;, &#123;6,0,2,5,M,M&#125;, &#123;3,2,0,3,4,M&#125;, &#123;M,5,3,0,2,3&#125;, &#123;M,M,4,2,0,5&#125;, &#123;M,M,M,3,5,0&#125;, &#125;; int start = 0; int[] shortPath = dijkstra(weight1, start); for (int i = 0; i &lt; shortPath.length; i++) System.out.println("从" + nodes[start] + "出发到" + nodes[i] + "的最短距离为：" + shortPath[i]); &#125; public static int[] dijkstra(int[][] weight, int start) &#123; // 接受一个有向图的权重矩阵，和一个起点编号start（从0编号，顶点存在数组中） // 返回一个int[] 数组，表示从start到它的最短路径长度 int n = weight.length; // 顶点个数 int[] shortPath = new int[n]; // 保存start到其他各点的最短路径 String[] path = new String[n]; // 保存start到其他各点最短路径的字符串表示 for (int i = 0; i &lt; n; i++) path[i] = new String(nodes[start] + "--&gt;" + nodes[i]); int[] visited = new int[n]; // 标记当前该顶点的最短路径是否已经求出,1表示已求出 // 初始化，第一个顶点已经求出 shortPath[start] = 0; visited[start] = 1; for (int count = 1; count &lt; n; count++) &#123; // 要加入n-1个顶点 int k = -1; // 选出一个距离初始顶点start最近的未标记顶点 int dmin = Integer.MAX_VALUE; for (int i = 0; i &lt; n; i++) &#123; if (visited[i] == 0 &amp;&amp; weight[start][i] &lt; dmin) &#123; dmin = weight[start][i]; k = i; &#125; &#125; // 将新选出的顶点标记为已求出最短路径，且到start的最短路径就是dmin shortPath[k] = dmin; visited[k] = 1; // 以k为中间点，修正从start到未访问各点的距离 for (int i = 0; i &lt; n; i++) &#123; //如果 '起始点到当前点距离' + '当前点到某点距离' &lt; '起始点到某点距离', 则更新 if (visited[i] == 0 &amp;&amp; weight[start][k] + weight[k][i] &lt; weight[start][i]) &#123; weight[start][i] = weight[start][k] + weight[k][i]; path[i] = path[k] + "--&gt;" + nodes[i]; &#125; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; System.out.println("从" + nodes[start] + "出发到" + nodes[i] + "的最短路径为：" + path[i]); &#125; System.out.println("====================================="); return shortPath; &#125;&#125; 运行结果12345678910111213从A出发到A的最短路径为：A--&gt;A从A出发到B的最短路径为：A--&gt;C--&gt;B从A出发到C的最短路径为：A--&gt;C从A出发到D的最短路径为：A--&gt;C--&gt;D从A出发到E的最短路径为：A--&gt;C--&gt;E从A出发到F的最短路径为：A--&gt;C--&gt;D--&gt;F=====================================从A出发到A的最短距离为：0从A出发到B的最短距离为：5从A出发到C的最短距离为：3从A出发到D的最短距离为：6从A出发到E的最短距离为：7从A出发到F的最短距离为：9 迪杰斯特拉(Dijkstra)算法适用于路径距离大于0（权值&gt;0）的最短路径计算，对带负权的图，应该用Floyd算法。 参考资料殷天文 简书 深入理解 Dijkstra 算法实现原理heroacool CSDN 数据结构–Dijkstra算法最清楚的讲解]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>最短路径</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分词原理]]></title>
    <url>%2F%E5%88%86%E8%AF%8D%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[英文中，一个单词就是一个词，而汉语中，以字为基本的书写单位，词语之间没有明显的区分标记，需要人为切分。根据其特点，可以把分词算法分为四大类： 基于规则的分词方法 基于统计的分词方法 基于语义的分词方法 基于理解的分词方法 基于规则的分词方法这种方法又叫作机械分词方法、基于字典的分词方法，它是按照一定的策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行匹配。若在词典中找到某个字符串，则匹配成功。该方法有三个要素，即分词词典、文本扫描顺序和匹配原则。文本的扫描顺序有正向扫描、逆向扫描和双向扫描。匹配原则主要有最大匹配、最小匹配、逐词匹配和最佳匹配。 最大匹配法（MM）。基本思想是：假设自动分词词典中的最长词条所含汉字的个数为 i，则取被处理材料当前字符串序列中的前i个字符作为匹配字段，查找分词词典，若词典中有这样一个i字词，则匹配成功，匹配字段作为一个词被切分出来；若词典中找不到这样的一个i字词，则匹配失败，匹配字段去掉最后一个汉字，剩下的字符作为新的匹配字段，再进行匹配，如此进行下去，直到匹配成功为止。统计结果表明，该方法的错误率为 1/169. 逆向最大匹配法（RMM）。该方法的分词过程与 MM 法相同，不同的是从句子（或文章）末尾开始处理，每次匹配不成功时去掉的是前面的一个汉字。统计结果表明，该方法的错误率为 1/245。 逐词遍历法。把词典中的词按照由长到短递减的顺序逐字搜索整个待处理的材料，一直到把全部的词切分出来为止。不论分词词典多大，被处理的材料多么小，都得把这个分词词典匹配一遍。 设立切分标志法。切分标志有自然和非自然之分。自然切分标志是指文章中出现的非文字符号，如标点符号等；非自然标志是利用词缀和不构成词的词（包 括单音词、复音节词以及象声词等）。设立切分标志法首先收集众多的切分标志，分词时先找出切分标志，把句子切分为一些较短的字段，再用 MM、RMM 或其它的方法进行细加工。这种方法并非真正意义上的分词方法，只是自动分词的一种前处理方式而已，它要额外消耗时间扫描切分标志，增加存储空间存放那些非 自然切分标志。 最佳匹配法（OM）。此法分为正向的最佳匹配法和逆向的最佳匹配法，其出发点是：在词典中按词频的大小顺序排列词条，以求缩短对分词词典的检索时 间，达到最佳效果，从而降低分词的时间复杂度，加快分词速度。实质上，这种方法也不是一种纯粹意义上的分词方法，它只是一种对分词词典的组织方式。OM 法的分词词典每条词的前面必须有指明长度的数据项，所以其空间复杂度有所增加，对提高分词精度没有影响，分词处理的时间复杂度有所降低。 此种方法优点是简单，易于实现。但缺点有很多：匹配速度慢；存在交集型和组合型歧义切分问题；词本身没有一个标准的定义，没有统一标准的词集；不同词典产生的歧义也不同；缺乏自学习的智能性。 基于统计的分词方法该方法的主要思想：词是稳定的组合，因此在上下文中，相邻的字同时出现的次数越多，就越有可能构成一个词。因此字与字相邻出现的概率或频率能较好地反映成词的可信度。可以对训练文本中相邻出现的各个字的组合的频度进行统计，计算它们之间的互现信息。互现信息体现了汉字之间结合关系的紧密程度。当紧密程 度高于某一个阈值时，便可以认为此字组可能构成了一个词。该方法又称为无字典分词。该方法所应用的主要的统计模型有：N 元文法模型（N-gram）、隐马尔可夫模型（Hiden Markov Model，HMM）、最大熵模型（ME）、条件随机场模型（Conditional Random Fields，CRF）等。在实际应用中此类分词算法一般是将其与基于词典的分词方法结合起来，既发挥匹配分词切分速度快、效率高的特点，又利用了无词典分词结合上下文识别生词、自动消除歧义的优点。 基于语义的分词方法语义分词法引入了语义分析，对自然语言自身的语言信息进行更多的处理，如扩充转移网络法、知识分词语义分析法、邻接约束法、综合匹配法、后缀分词法、特征词库法、矩阵约束法、语法分析法等。 扩充转移网络法。该方法以有限状态机概念为基础。有限状态机只能识别正则语言，对有限状态机作的第一次扩充使其具有递归能力，形成递归转移网络 （RTN）。在RTN 中，弧线上的标志不仅可以是终极符（语言中的单词）或非终极符（词类），还可以调用另外的子网络名字分非终极符（如字或字串的成词条件）。这样，计算机在 运行某个子网络时，就可以调用另外的子网络，还可以递归调用。词法扩充转移网络的使用， 使分词处理和语言理解的句法处理阶段交互成为可能，并且有效地解决了汉语分词的歧义。 矩阵约束法。其基本思想是：先建立一个语法约束矩阵和一个语义约束矩阵， 其中元素分别表明具有某词性的词和具有另一词性的词相邻是否符合语法规则， 属于某语义类的词和属于另一词义类的词相邻是否符合逻辑，机器在切分时以之约束分词结果。 基于理解的分词方法基于理解的分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。它通常包括三个部分：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。目前基于理解的分词方法主要有专家系统分词法和神经网络分词法等。 专家系统分词法。从专家系统角度把分词的知识（包括常识性分词知识与消除歧义切分的启发性知识即歧义切分规则）从实现分词过程的推理机中独立出来，使知识库的维护与推理机的实现互不干扰，从而使知识库易于维护和管理。它还具有发现交集歧义字段和多义组合歧义字段的能力和一定的自学习功能。 神经网络分词法。该方法是模拟人脑并行，分布处理和建立数值计算模型工作的。它将分词知识所分散隐式的方法存入神经网络内部，通过自学习和训练修改内部权值，以达到正确的分词结果，最后给出神经网络自动分词结果，如使用 LSTM、GRU 等神经网络模型等。 神经网络与专家系统结合分词法。该方法首先启动神经网络进行分词，当神经网络对新出现的词不能给出准确切分时，激活专家系统进行分析判断，依据知识库进行推理，得出初步分析，并启动学习机制对神经网络进行训练。该方法可以较充分发挥神经网络与专家系统二者优势，进一步提高分词效率。 参考资料Judikator 简书 中文分词原理及常用Python中文分词库介绍]]></content>
      <categories>
        <category>数学之美</category>
      </categories>
      <tags>
        <tag>分词</tag>
        <tag>原理</tag>
      </tags>
  </entry>
</search>
